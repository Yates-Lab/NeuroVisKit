{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularization Tutorial\n",
    "NeuroVisKit aims to reduce the burden of using explicit regularizations by modularizing and automating the manual steps involved.\n",
    "### Minimal Usage\n",
    "First We will show a minimal example of using regularization in a model. A popular type of regularization is energy or L2 regularization, so we will implement that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2 penalty is 0.003\n"
     ]
    }
   ],
   "source": [
    "import NeuroVisKit.utils.regularization as reg\n",
    "import torch.nn as nn\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(10, 10) #arbitrary model\n",
    "        self.energy_reg = reg.l2(1e-3, target=self.fc1.weight) #this will add 1e-3 weighted reg term to the loss\n",
    "model = Model()\n",
    "\n",
    "#calculate penalty every training step\n",
    "penalty = model.energy_reg()\n",
    "print(f\"L2 penalty is {penalty.item():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Traditionally, the regularization penalty is manually added to the loss. However, NeuroVisKit allows for automation using our PytorchWrapper. PytorchWrapper automatically extracts all regularization modules from a model.\n",
    "\n",
    "Regular regularization penalties are then automatically added to the loss, the optimizer should step, and then proximal regularization should take place. For more information in proximal regularization, I recommend checking out the [wikipedia](https://en.wikipedia.org/wiki/Proximal_gradient_methods_for_learning) page or looking it up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialized modules: [l2()] proximal modules: []\n"
     ]
    }
   ],
   "source": [
    "from NeuroVisKit.utils import PytorchWrapper\n",
    "wrapped_model = PytorchWrapper(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding new modules\n",
    "Taking a step back, lets take a look at which regularization modules come with NeuroVisKit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['activityL1',\n",
       " 'activityL1Sum',\n",
       " 'activityL2',\n",
       " 'proximalGroupSparsity',\n",
       " 'proximalSparsityDekel',\n",
       " 'proximalL1',\n",
       " 'proximalP05',\n",
       " 'proximalL2',\n",
       " 'l1',\n",
       " 'l2',\n",
       " 'l4',\n",
       " 'max',\n",
       " 'local',\n",
       " 'glocal',\n",
       " 'fourierLocal',\n",
       " 'edge',\n",
       " 'center',\n",
       " 'fourierCenter',\n",
       " 'localConv',\n",
       " 'laplacian']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(reg.get_regs_dict().keys()) #get all regularization modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding a new reg module is super easy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewRegModule(reg.RegularizationModule):\n",
    "    def function(self): #implement your own regularization function\n",
    "        return self.target.norm(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And adding a new proximal reg module is also super easy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewRegModule(reg.ProximalRegularizationModule):\n",
    "    def proximal(self): #implement your own proximal step\n",
    "        penalty = (self.target.data.abs() - 1).clamp(min=0).mean() #proximal penalty for logging\n",
    "        self.target.data = self.target.data.sign() * self.target.data.abs().clamp(max=1) #proximal step\n",
    "        return penalty #return a penalty for logging\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "v11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
